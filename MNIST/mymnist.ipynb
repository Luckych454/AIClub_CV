{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINST: 从0到1%:第一次提交\n",
    "\n",
    "在我们学习深度学习的时候，往往会用最简单的MNIST数据集作为我们的开始。在这里我用kaggle上的 digit-recognizer为初学者作为讲解。\n",
    "Kaggle传送门: [digit-recognizer](https://www.kaggle.com/c/digit-recognizer) \n",
    "我们目的并不是成为kaggle上的1%,我希望通过这篇文章，大家能对CV上的训练有一个最最简单的认识，并且对参加kaggle竞赛的过程有一个理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#本文我们使用的是pytorch 1.0.0\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np #numpy 是一个极其重要的库，据说75%的机器学习项目都用了numpy\n",
    "# pytorch是个代码即文档的库，我建议如果你想搞懂pytoch的话，可以直接看代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们对kaggle下载的数据解压，并处理，在这里我已经下好了，得到的就是test.csv, train.csv, sample_submission.csv三个文件。\n",
    "接下来我们利用pytorch中的Dataset和DataLoader对数据进行处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_img = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "#将numpy数组转为pytorch训练的tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打开从kaggle下载的train.csv，可以看到他给我们的文件其实就是一个label和一个一维化的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "train_path = \"train.csv\"\n",
    "try_data = pd.read_csv(train_path,skiprows = 0)\n",
    "print(try_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 继承Dataset\n",
    "\n",
    "然后我们从pytorch的Dataset那里继承我们的MNISTDataset，我们把训练用的item从读入的1维的图像转为3维的。这里我们将一个图像转为[1,28,28]形状的，主要是适应pytorch自带的MNIST数据集，这是后话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self,csv_file,transform=None):\n",
    "        data = pd.read_csv(csv_file,skiprows=0)\n",
    "        self.X = np.array(data.iloc[:,1:]).reshape(-1,28,28,1).astype('float32')\n",
    "        self.X /= 255\n",
    "        self.y = np.array(data.iloc[:,0])\n",
    "        del data\n",
    "        self.transfrom = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.X[idx]\n",
    "        label = torch.from_numpy(np.array(self.y[idx]))\n",
    "        if(self.transfrom):\n",
    "            item = self.transfrom(item)\n",
    "        return (item,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50 #batch_size是一次训练读入的图片数量\n",
    "kaggle_trainset = MNISTDataset(csv_file='train.csv',transform=trans_img)\n",
    "print(kaggle_trainset.__getitem__(0)[0].shape)\n",
    "kaggle_trainloader = DataLoader(dataset = kaggle_trainset,batch_size=batch_size,shuffle=True)\n",
    "#shuffle 是训练集是否随机读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一个model\n",
    "\n",
    "通过DataLoader我们就获取到了一个适合训练的训练集了。然后我们就好建立我们的模型了。在这里我们使用的是著名的Lenet-5模型，很简单，大家可以百度一下，大致就是两个卷积两个池化最后来三个全连接。具体的模型可以自己看看教程或者直接看论文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#pytorch 的网络层都在nn里面，我建议之间看pytorch的代码\n",
    "#另外 pytorch的激活函数是在 nn.functional 里面\n",
    "#最简单的lenet-5\n",
    "class Lenet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5,stride=1,padding=2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5, stride= 1, padding=0)\n",
    "        self.fc1 = nn.Linear(400,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(self.conv1(x),(2,2))\n",
    "        out = F.max_pool2d(self.conv2(out),(2,2))\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练模型\n",
    "\n",
    "接下来我们肯定要迫不及待地试验一下我们模型的结果啦。怎么看效果呢，这时候我们就能使用pytorch自带的MNIST数据集来验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "MNIST_vaildset = MNIST('./data', train=False,download = False ,transform=trans_img)\n",
    "# 如果是第一次使用，需要将download改成True，等待的事件可能还有点久\n",
    "MNIST_vaildloader = DataLoader(MNIST_vaildset,batch_size=batch_size,shuffle = True)\n",
    "#使用pytorch自带的验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "def train(model,trainloader,optimizer,epoch,epoches):\n",
    "    criterian = nn.CrossEntropyLoss(size_average=False)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    for (img, label) in trainloader:\n",
    "        if torch.cuda.is_available():\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        loss = criterian(output, label)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data\n",
    "        _, predict = torch.max(output, 1)\n",
    "        correct_num = (predict == label).sum()\n",
    "        running_acc += correct_num.item()\n",
    "    running_loss /= len(trainloader.dataset)\n",
    "    running_acc /= len(trainloader.dataset)\n",
    "    print(\"[%d/%d] Loss: %f, Acc: %f\" % (epoch + 1, epoches, running_loss, 100 * running_acc))\n",
    "    \n",
    "def vaild(model,vaildloader):\n",
    "    criterian = nn.CrossEntropyLoss(size_average=False)\n",
    "    vaildloss = 0.\n",
    "    vaildacc = 0.\n",
    "    for (img, label) in MNIST_vaildloader:\n",
    "        img = Variable(img).cuda()\n",
    "        label = Variable(label).cuda()\n",
    "        output = model(img)\n",
    "        loss = criterian(output, label)\n",
    "        vaildloss += loss.data\n",
    "        _, predict = torch.max(output, 1)\n",
    "        num_correct = (predict == label).sum()\n",
    "        vaildacc += num_correct.item()\n",
    "    vaildloss /= len(vaildloader.dataset)\n",
    "    vaildacc /= len(vaildloader.dataset)\n",
    "    print(\"Test: Loss: %.5f, Acc: %.2f %%\" % (vaildloss, 100 * vaildacc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/20] Loss: 0.527811, Acc: 83.811905\n",
      "[2/20] Loss: 0.127143, Acc: 96.119048\n",
      "[3/20] Loss: 0.090400, Acc: 97.254762\n",
      "[4/20] Loss: 0.073504, Acc: 97.766667\n",
      "[5/20] Loss: 0.063877, Acc: 98.045238\n",
      "[6/20] Loss: 0.058642, Acc: 98.150000\n",
      "[7/20] Loss: 0.051914, Acc: 98.357143\n",
      "[8/20] Loss: 0.047743, Acc: 98.445238\n",
      "[9/20] Loss: 0.044504, Acc: 98.600000\n",
      "[10/20] Loss: 0.041794, Acc: 98.697619\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-65664d056e5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlenet1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkaggle_trainloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mvaild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlenet1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvaildloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMNIST_vaildloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-cc4488852adf>\u001b[0m in \u001b[0;36mvaild\u001b[0;34m(model, vaildloader)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mnum_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mvaildacc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum_correct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mvaildloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvaildloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mvaildacc\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvaildloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "epoches = 20\n",
    "lenet1 = Lenet1()\n",
    "if torch.cuda.is_available():\n",
    "    lenet1.cuda()\n",
    "optimizer1 = optim.SGD(lenet1.parameters(), lr=learning_rate)\n",
    "for epoch in range(epoches):\n",
    "    train(model=lenet1,trainloader=kaggle_trainloader,optimizer=optimizer1,epoch=epoch,epoches=epoches)\n",
    "    if (epoch+1)%10 == 0:\n",
    "        vaild(model = lenet1,vaildloader=MNIST_vaildloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改进模型\n",
    "\n",
    "理论上来说，在20次的迭代后这个模型能达到99%的正确率，但是我们的目标可是成为~~海贼王的男人~~100%，那么就要改进一下啦。\n",
    "通过从网上找资料，我发现了激活函数这个好东西，好像说这几年的深度学习能这么好，有很大的功劳是激活函数的不断发展。\n",
    "那么我们不如就试一下把一些激活函数套上我们平凡的lenet模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/20] Loss: 0.856990, Acc: 71.078571\n",
      "[2/20] Loss: 0.114097, Acc: 96.438095\n",
      "[3/20] Loss: 0.079466, Acc: 97.440476\n",
      "[4/20] Loss: 0.061130, Acc: 98.030952\n",
      "[5/20] Loss: 0.048927, Acc: 98.423810\n",
      "[6/20] Loss: 0.042337, Acc: 98.592857\n",
      "[7/20] Loss: 0.036742, Acc: 98.773810\n",
      "[8/20] Loss: 0.032797, Acc: 98.859524\n",
      "[9/20] Loss: 0.027252, Acc: 99.140476\n",
      "[10/20] Loss: 0.026037, Acc: 99.114286\n",
      "Test: Loss: 0.02427, Acc: 99.24 %\n",
      "[11/20] Loss: 0.020766, Acc: 99.319048\n",
      "[12/20] Loss: 0.019176, Acc: 99.333333\n",
      "[13/20] Loss: 0.016288, Acc: 99.438095\n",
      "[14/20] Loss: 0.013642, Acc: 99.569048\n",
      "[15/20] Loss: 0.012957, Acc: 99.597619\n",
      "[16/20] Loss: 0.011243, Acc: 99.630952\n",
      "[17/20] Loss: 0.010216, Acc: 99.671429\n",
      "[18/20] Loss: 0.009779, Acc: 99.650000\n",
      "[19/20] Loss: 0.006942, Acc: 99.819048\n",
      "[20/20] Loss: 0.006559, Acc: 99.778571\n",
      "Test: Loss: 0.01363, Acc: 99.66 %\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "epoches = 20\n",
    "class Lenet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5,stride=1,padding=2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5, stride= 1, padding=0)\n",
    "        self.fc1 = nn.Linear(400,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        out = F.max_pool2d(F.relu(self.conv2(out)),(2,2))\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "lenet2 = Lenet2()\n",
    "if torch.cuda.is_available():\n",
    "    lenet2.cuda()\n",
    "optimizer2 = optim.SGD(lenet2.parameters(), lr=learning_rate)\n",
    "for epoch in range(epoches):\n",
    "    train(model=lenet2,trainloader=kaggle_trainloader,optimizer=optimizer2,epoch=epoch,epoches=epoches)\n",
    "    if (epoch+1)%10 == 0:\n",
    "        vaild(model = lenet2,vaildloader=MNIST_vaildloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果来看，稍微好了那么一点点，但是我们不满足啊，我们一定要继续努力，从而变得更~~秃~~强!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type Lenet2. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(lenet2,\"mnist.pkl\")\n",
    "#保存我们的lenet2模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建测试集的Dataset\n",
    "\n",
    "打开test.csv我们可以看到它和train.csv的数据是不一样的，因此我们以为test.csv也创建一个Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class testdata(Dataset):\n",
    "    def __init__(self,csv_file,transform = None):\n",
    "        data = pd.read_csv(csv_file, skiprows=0)\n",
    "        self.X = np.array(data).reshape(-1, 28, 28, 1).astype('float32')\n",
    "        self.X /= 255\n",
    "        del data\n",
    "        self.transfrom = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.X[idx]\n",
    "        if(self.transfrom):\n",
    "            item = self.transfrom(item)\n",
    "        return item\n",
    "\n",
    "testdataset = testdata(\"test.csv\",transform=trans_img)\n",
    "testloader = DataLoader(dataset=testdataset,batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出测试结果\n",
    "\n",
    "除了两个数据集，kaggle给我们的还有一个sample_submission.csv,我们需要仿照这个格式提交我们的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,dataloader,path):\n",
    "    model.eval() #固定model的参数\n",
    "    f = open(path,'w')\n",
    "    f.write('ImageId,Label\\n')\n",
    "    i = 1\n",
    "    for img in testloader:\n",
    "        if torch.cuda.is_available():\n",
    "            img = Variable(img).cuda()\n",
    "        output = model(img)\n",
    "        _, predict = torch.max(output, 1)\n",
    "        for it in predict:\n",
    "            f.write(str(i)+','+str(it.item())+'\\n')\n",
    "            i += 1\n",
    "    f.close\n",
    "    print(\"OK!\")\n",
    "model = torch.load(\"mnist.pkl\")\n",
    "test(model,testloader,'submit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 提交模型\n",
    "\n",
    "现在就能把得到的submit.csv交上去，然后得到第一个kaggle排名！\n",
    "我们这里的迭代次数只有20次，可以通过更多的迭代得到更好的模型，但是更过的迭代的结果往往是过拟合，那么应该怎么解决呢？且听下回分解。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
