{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINST: 从0到1%\n",
    "\n",
    "在我们学习深度学习的时候，往往会用最简单的MNIST数据集作为我们的开始。在这里我用kaggle上的 digit-recognizer为初学者作为讲解。\n",
    "Kaggle传送门: [digit-recognizer](https://www.kaggle.com/c/digit-recognizer) \n",
    "我们目的并不是成为kaggle上的1%,我希望通过这篇文章，大家能对CV上的训练有一个最最简单的认识，并且对参加kaggle竞赛的过程有一个理解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#本文我们使用的是pytorch 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先我们对kaggle下载的数据解压，并处理，在这里我已经下好了，得到的就是test.csv, train.csv, sample_submission.csv三个文件。\n",
    "接下来我们利用pytorch中的Dataset和DataLoader对数据进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np #numpy 是一个极其重要的库，据说75%的机器学习项目都用了numpy\n",
    "# pytorch是个代码即文档的库，我建议如果你想搞懂pytoch的话，可以直接看代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_img = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "#将numpy数组转为pytorch训练的tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你打开kaggle下载的train.csv你可以看到他给我们的文件其实就是一个label后面接上一维化的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "train_path = \"train.csv\"\n",
    "try_data = pd.read_csv(train_path,skiprows = 0)\n",
    "print(try_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们从pytorch的Dataset那里继承我们的MNISTDataset，我们把训练用的item从读入的1维的图像转为3维的。这里我们将一个图像转为[1,28,28]形状的，主要是适应pytorch自带的MNIST数据集，这是后话。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self,csv_file,transform=None):\n",
    "        data = pd.read_csv(csv_file,skiprows=0)\n",
    "        self.X = np.array(data.iloc[:,1:]).reshape(-1,28,28,1).astype('float32')\n",
    "        self.X /= 255\n",
    "        self.y = np.array(data.iloc[:,0])\n",
    "        del data\n",
    "        self.transfrom = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.X[idx]\n",
    "        label = torch.from_numpy(np.array(self.y[idx]))\n",
    "        if(self.transfrom):\n",
    "            item = self.transfrom(item)\n",
    "        return (item,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50 #batch_size是一次训练读入的图片数量\n",
    "kaggle_trainset = MNISTDataset(csv_file='train.csv',transform=trans_img)\n",
    "print(kaggle_trainset.__getitem__(0)[0].shape)\n",
    "kaggle_trainloader = DataLoader(dataset = kaggle_trainset,batch_size=batch_size,shuffle=True)\n",
    "#shuffle 是训练集是否随机读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过DataLoader我们就获取到了一个适合训练的训练集了。然后我们就好建立我们的模型了。在这里我们使用的是著名的Lenet-5模型，很简单，大家可以上网搜一下，大致就是两个卷积两个池化最后来三个全连接。具体的模型可以自己看看论文。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#pytorch 的网络层都在nn里面，我建议之间看pytorch的代码\n",
    "#另外 pytorch的激活函数是在 nn.functional 里面\n",
    "#最简单的lenet-5\n",
    "class Lenet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5,stride=1,padding=2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5, stride= 1, padding=0)\n",
    "        self.fc1 = nn.Linear(400,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(self.conv1(x),(2,2))\n",
    "        out = F.max_pool2d(self.conv2(out),(2,2))\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们肯定要迫不及待地试验一下我们模型的结果啦。怎么看效果呢，这时候我们就能使用pytorch自带的MNIST数据集来验证。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "MNIST_vaildset = MNIST('./data', train=False,transform=trans_img)\n",
    "MNIST_vaildloader = DataLoader(MNIST_vaildset,batch_size=batch_size,shuffle = True)\n",
    "#使用pytorch自带的验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "def train(model,trainloader,optimizer,epoch,epoches):\n",
    "    criterian = nn.CrossEntropyLoss(size_average=False)\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "    for (img, label) in trainloader:\n",
    "        if torch.cuda.is_available():\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(img)\n",
    "        loss = criterian(output, label)\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data\n",
    "        _, predict = torch.max(output, 1)\n",
    "        correct_num = (predict == label).sum()\n",
    "        running_acc += correct_num.item()\n",
    "    running_loss /= len(trainloader.dataset)\n",
    "    running_acc /= len(trainloader.dataset)\n",
    "    print(\"[%d/%d] Loss: %f, Acc: %f\" % (epoch + 1, epoches, running_loss, 100 * running_acc))\n",
    "    \n",
    "def vaild(model,vaildloader):\n",
    "    criterian = nn.CrossEntropyLoss(size_average=False)\n",
    "    vaildloss = 0.\n",
    "    vaildacc = 0.\n",
    "    for (img, label) in MNIST_vaildloader:\n",
    "        img = Variable(img).cuda()\n",
    "        label = Variable(label).cuda()\n",
    "        output = model(img)\n",
    "        loss = criterian(output, label)\n",
    "        vaildloss += loss.data\n",
    "        _, predict = torch.max(output, 1)\n",
    "        num_correct = (predict == label).sum()\n",
    "        vaildacc += num_correct.item()\n",
    "    vaildloss /= len(vaildloader.dataset)\n",
    "    vaildacc /= len(vaildloader.dataset)\n",
    "    print(\"Test: Loss: %.5f, Acc: %.2f %%\" % (vaildloss, 100 * vaildacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/20] Loss: 0.522027, Acc: 84.059524\n",
      "[2/20] Loss: 0.126681, Acc: 96.097619\n",
      "[3/20] Loss: 0.092063, Acc: 97.161905\n",
      "[4/20] Loss: 0.077288, Acc: 97.611905\n",
      "[5/20] Loss: 0.064520, Acc: 97.947619\n",
      "[6/20] Loss: 0.057005, Acc: 98.226190\n",
      "[7/20] Loss: 0.051071, Acc: 98.416667\n",
      "[8/20] Loss: 0.047151, Acc: 98.495238\n",
      "[9/20] Loss: 0.044016, Acc: 98.645238\n",
      "[10/20] Loss: 0.040574, Acc: 98.750000\n",
      "Test: Loss: 0.03127, Acc: 99.01 %\n",
      "[11/20] Loss: 0.037369, Acc: 98.833333\n",
      "[12/20] Loss: 0.035347, Acc: 98.852381\n",
      "[13/20] Loss: 0.032064, Acc: 98.971429\n",
      "[14/20] Loss: 0.032032, Acc: 99.000000\n",
      "[15/20] Loss: 0.029067, Acc: 99.026190\n",
      "[16/20] Loss: 0.027322, Acc: 99.114286\n",
      "[17/20] Loss: 0.027320, Acc: 99.069048\n",
      "[18/20] Loss: 0.024955, Acc: 99.183333\n",
      "[19/20] Loss: 0.024194, Acc: 99.214286\n",
      "[20/20] Loss: 0.023087, Acc: 99.211905\n",
      "Test: Loss: 0.03010, Acc: 99.10 %\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "epoches = 20\n",
    "lenet1 = Lenet1()\n",
    "if torch.cuda.is_available():\n",
    "    lenet1.cuda()\n",
    "optimizer1 = optim.SGD(lenet1.parameters(), lr=learning_rate)\n",
    "for epoch in range(epoches):\n",
    "    train(model=lenet1,trainloader=kaggle_trainloader,optimizer=optimizer1,epoch=epoch,epoches=epoches)\n",
    "    if (epoch+1)%10 == 0:\n",
    "        vaild(model = lenet1,vaildloader=MNIST_vaildloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理论上来说，在20次的迭代后这个模型能达到99%的正确率，但是我们的目标可是成为~~海贼王的男人~~100%，那么就要改进一下啦。\n",
    "通过从网上找资料，我发现了激活函数这个好东西，好像说这几年的深度学习能这么好，有很大的功劳是激活函数的不断发展。\n",
    "那么我们不如就试一下把一些激活函数套上我们平凡的lenet模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/20] Loss: 0.993573, Acc: 66.359524\n",
      "[2/20] Loss: 0.126021, Acc: 95.980952\n",
      "[3/20] Loss: 0.081728, Acc: 97.371429\n",
      "[4/20] Loss: 0.065245, Acc: 98.011905\n",
      "[5/20] Loss: 0.053575, Acc: 98.271429\n",
      "[6/20] Loss: 0.045406, Acc: 98.523810\n",
      "[7/20] Loss: 0.039177, Acc: 98.759524\n",
      "[8/20] Loss: 0.034390, Acc: 98.933333\n",
      "[9/20] Loss: 0.029394, Acc: 99.047619\n",
      "[10/20] Loss: 0.026382, Acc: 99.140476\n",
      "Test: Loss: 0.02346, Acc: 99.31 %\n",
      "[11/20] Loss: 0.022648, Acc: 99.233333\n",
      "[12/20] Loss: 0.020471, Acc: 99.328571\n",
      "[13/20] Loss: 0.017709, Acc: 99.457143\n",
      "[14/20] Loss: 0.015819, Acc: 99.485714\n",
      "[15/20] Loss: 0.015143, Acc: 99.521429\n",
      "[16/20] Loss: 0.012266, Acc: 99.640476\n",
      "[17/20] Loss: 0.011666, Acc: 99.621429\n",
      "[18/20] Loss: 0.010683, Acc: 99.669048\n",
      "[19/20] Loss: 0.007827, Acc: 99.759524\n",
      "[20/20] Loss: 0.008825, Acc: 99.714286\n",
      "Test: Loss: 0.02524, Acc: 99.37 %\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "epoches = 20\n",
    "class Lenet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Lenet2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,5,stride=1,padding=2)\n",
    "        self.conv2 = nn.Conv2d(6,16,5, stride= 1, padding=0)\n",
    "        self.fc1 = nn.Linear(400,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.relu(self.conv1(x)),(2,2))\n",
    "        out = F.max_pool2d(F.relu(self.conv2(out)),(2,2))\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "lenet2 = Lenet2()\n",
    "if torch.cuda.is_available():\n",
    "    lenet2.cuda()\n",
    "optimizer2 = optim.SGD(lenet2.parameters(), lr=learning_rate)\n",
    "for epoch in range(epoches):\n",
    "    train(model=lenet2,trainloader=kaggle_trainloader,optimizer=optimizer2,epoch=epoch,epoches=epoches)\n",
    "    if (epoch+1)%10 == 0:\n",
    "        vaild(model = lenet2,vaildloader=MNIST_vaildloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从结果来看，稍微好了那么一点点，但是我们不满足啊，我们一定要继续努力，从而变得更~~秃~~强!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
